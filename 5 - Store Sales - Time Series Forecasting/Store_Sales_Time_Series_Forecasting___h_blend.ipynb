{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 29781,
          "databundleVersionId": 2887556,
          "isSourceIdPinned": false,
          "sourceType": "competition"
        },
        {
          "sourceId": 14258843,
          "sourceType": "datasetVersion",
          "datasetId": 9098418
        }
      ],
      "dockerImageVersionId": 31239,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Store Sales - Time Series Forecasting | h-blend",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "L-myrKa82O-d"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "store_sales_time_series_forecasting_path = kagglehub.competition_download('store-sales-time-series-forecasting')\n",
        "nina2025_2025_12_22_store_sales_time_series_forecasting_path = kagglehub.dataset_download('nina2025/2025-12-22-store-sales-time-series-forecasting')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "jcdSW66A2O-k"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Store Sales - Time Series Forecasting](https://www.kaggle.com/competitions/store-sales-time-series-forecasting/code?competitionId=29781&sortBy=scoreAscending&excludeNonAccessedDatasources=true)\n",
        "\n",
        "Use machine learning to predict grocery sales\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Dear developers, you can add other participants to the group. Or create different groups and then \"friendly intersect\" their results at the second level of the blend. For example, like [here](https://www.kaggle.com/code/nina2025/ps-s5e12-hb20g).\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "| | | &nbsp; | | &nbsp; | &nbsp; | &nbsp; | &nbsp; |\n",
        "|:-|:-| :-: | :-: | :-: | :-: | :-: | :-: |\n",
        "| 1. | [0.37_982](https://www.kaggle.com/code/ivanlydkin/time-series-course-a-practical-guide/notebook?scriptVersionId=148615046) |&nbsp;v.18&nbsp;| [ðŸ•’Time Series Course: A Practical Guide](https://www.kaggle.com/code/ivanlydkin/time-series-course-a-practical-guide/notebook) | expert | [Ivan Lydkin](https://www.kaggle.com/ivanlydkin) | Kyrgyzstan |\n",
        "| 2. | [0.37_984](https://www.kaggle.com/code/chongzhenjie/ecuador-store-sales-global-forecasting-lightgbm?scriptVersionId=134603190) |&nbsp;v.1&nbsp;| [Ecuador Store Sales â€” Global Forecasting LightGBM](https://www.kaggle.com/code/chongzhenjie/ecuador-store-sales-global-forecasting-lightgbm) | contributor | [Chong Zhen Jie](https://www.kaggle.com/chongzhenjie) | World |\n",
        "| 3. | [0.38_006](https://www.kaggle.com/code/dangnguyen97/0-38006-lightgbm?scriptVersionId=143541371) |&nbsp;v.1&nbsp;| [0.38006 - LightGBM](https://www.kaggle.com/code/dangnguyen97/0-38006-lightgbm) | master | [dangnguyen_97](https://www.kaggle.com/dangnguyen97) | Vietnam |\n",
        "| 4. | [0.38_040](https://www.kaggle.com/code/dmitryshekhov/darts-ensemble-with-lightgbm-stacking?scriptVersionId=130511677) |&nbsp;v.4&nbsp;| [Darts Ensemble with LightGBM Stacking](https://www.kaggle.com/code/dmitryshekhov/darts-ensemble-with-lightgbm-stacking) | expert | [Dmitry Shekhov](https://www.kaggle.com/dmitryshekhov) | World |\n",
        "||||||||\n",
        "||h-blend||**main weight**|**asc/desc**|**correct weight**|\n",
        "|  | [0.37_950](https://www.kaggle.com/code/nina2025/store-sales-time-series-forecasting-h-blend?scriptVersionId=287850388) | [v.1](#h-blend) | [ 1.,2.,3.,4. ] . [[ +0.25 +0.25 +0.25 +0.25 ](#h-blend)] | 30 x 70 | [[ +11, &nbsp;-1, -3, -7 ](#h-blend)] / 100 |\n",
        "|  | [0.37_946](https://www.kaggle.com/code/nina2025/store-sales-time-series-forecasting-h-blend?scriptVersionId=287852111) | [v.2](#Version.2,3,5) | [ 1.,3.,4. ] . [[ +0.334 +0.333 +0.333 ](#Version.2,3,5)] | 30 x 70 | [[ +10, &nbsp;-3, -7 ](#Version.2,3,5)] / 100 |\n",
        "|  | [0.37_967](https://www.kaggle.com/code/nina2025/store-sales-time-series-forecasting-h-blend?scriptVersionId=287853259) | [v.3](#Version.2,3,5) | [ 1.,3.,4. ] . [[ +0.70 +0.20 +0.10 ](#Version.2,3,5)] | 30 x 70 | [[ +10, &nbsp;-3, -7 ](#Version.2,3,5)] / 100 |\n",
        "|  | [0.37_948](https://www.kaggle.com/code/nina2025/store-sales-time-series-forecasting-h-blend?scriptVersionId=287856725) | [v.4](#Version.1,4) | [ 1.,2.,3.,4. ] . [[ +0.30 +0.10 +0.30 +0.30 ](#Version.1,4)] | 30 x 70 | [[ +14,&nbsp; -1,-5,-8 ](#Version.1,4)] / 100 |\n",
        "||||||||\n",
        "|  | [?](https://www.kaggle.com/code/nina2025/store-sales-time-series-forecasting-h-blend) | [v.5](#Version.2,3,5) | [ 1.,3.,4. ] . [[ +0.37 +0.33 +0.30 ](#Version.2,3,5)] | 30 x 70 | [[ +10, &nbsp;-3, -7 ](#Version.2,3,5)] / 100 |\n",
        "||||||||"
      ],
      "metadata": {
        "id": "Flku3fsp2O-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os,ast,shutil,copy\n",
        "\n",
        "from bokeh.plotting import figure, gridplot\n",
        "from bokeh.io import output_file, show, output_notebook\n",
        "output_notebook()\n",
        "\n",
        "\n",
        "def bokeh_show(\n",
        "        params,\n",
        "        df_cross,\n",
        "        show_figures1,\n",
        "        show_figures2, wps_fig2,\n",
        "        color_cross):\n",
        "\n",
        "    colors = [subm['color'] for subm in params['subm']]\n",
        "\n",
        "    def dossier(js,subms,cols):\n",
        "        def quant(i,js,subms,cols):\n",
        "            return {\"c\" : i, \"q\" : sum([1 for subm in cols[i] if subm == subms[js]])}\n",
        "        return {\n",
        "            'name' : subms[js],\n",
        "            'q_in' : [quant(i,js,subms,cols) for i in range(len(subms))]\n",
        "        }\n",
        "    alls = pd.read_csv(f'tida_desc.csv')\n",
        "    matrix = [ast.literal_eval(str(row.alls)) for row in alls.itertuples()]\n",
        "    subms = sorted(matrix[0])\n",
        "    cols = [[data[i] for data in matrix] for i in range(len(subms))]\n",
        "    df_subms = pd.DataFrame({f'col_{i}': [x[i] for x in matrix] for i in range(len(subms))})\n",
        "    dossiers = [dossier(js,subms,cols) for js in range(len(subms))]\n",
        "    subm_names = [one_dossier['name'] for one_dossier in dossiers]\n",
        "    figures1,qss,i = [],[],0\n",
        "    height = 100 if len(colors)==2\\\n",
        "        else 134 if len(colors)==3 else (154 if len(colors)==4 else 174)\n",
        "    for one_dossier in dossiers:\n",
        "        i_col = 'alls. ' + str(one_dossier['q_in'][i]['c'])\n",
        "        qs = [one['q'] for one in one_dossier['q_in']]\n",
        "        x_names = [name.replace(\"Group\",\"\").replace(\"subm_\",\"\") for name in subm_names]\n",
        "        width = 157  if len(colors) == 5\\\n",
        "            else (140 if len(colors) == 4\\\n",
        "            else (121 if len(colors) == 8\\\n",
        "            else (131 if len(colors) == 9\\\n",
        "            else (141 if len(colors) == 10\\\n",
        "            else (171 if len(colors) == 11 else 130)))))\n",
        "        f = figure(x_range=x_names,width=width, height=height, title=i_col)\n",
        "        f.vbar(x=x_names, width=0.585, top=qs, color=colors)\n",
        "        figures1.append(f)\n",
        "        qss.append(qs)\n",
        "        i+=1\n",
        "    grid = gridplot([figures1])\n",
        "    output_file('tida_alls.html')\n",
        "    if show_figures1 == True: show(grid)\n",
        "    sub_wts = params['subwts']\n",
        "    main_wts = [subm['weight'] for subm in params['subm']]\n",
        "    mms,acc_mass = [],[]\n",
        "    for j in range(len(dossiers)):\n",
        "        one_dossier = dossiers[j]\n",
        "        qs = [one['q'] for one in one_dossier['q_in']]\n",
        "        mm = [qs[h] * (main_wts[j] + sub_wts[h]) for h in range(len(sub_wts))]\n",
        "        mass = sum(mm)\n",
        "        mms.append(mm)\n",
        "        acc_mass.append(round(mass))                        #subm_names[::-1]\n",
        "    y_names = [name + \" - \" + str(mass) for name,mass in zip(subm_names,acc_mass)]\n",
        "    f1 = figure(y_range=y_names, width=270, height=height, title='relations of general masses')\n",
        "    f1.hbar(y=y_names, height=0.555, right=acc_mass, left=0, color=colors)\n",
        "    output_file('tida_alls2.html')\n",
        "    alls = [f'alls.{i}' for i in range(len(dossiers))]\n",
        "    subm = [f'sub{i}'   for i in range(len(dossiers))]\n",
        "    mmsT  = np.asarray(mms).T\n",
        "    data = {'cols' : alls}\n",
        "    for i in range(len(dossiers)): data[f'sub{i}'] = mmsT[i,:]\n",
        "    f2 = figure(y_range=alls, height=height, width=270, title=\"relations of columns masses\")\n",
        "    f2.hbar_stack(subm, y='cols', height=0.555, color=colors, source=data)\n",
        "    qssT  = np.asarray(qss).T\n",
        "    data = {'cols' : alls}\n",
        "    for i in range(len(dossiers)): data[f'sub{i}'] = qssT[i,:]\n",
        "    f3 = figure(y_range=alls, height=height, width=245, title=\"ratios in columns\")\n",
        "    f3.hbar_stack(subm, y='cols', height=0.555, color=colors, source=data)\n",
        "    grid = gridplot([[f3,f2,f1]])\n",
        "    show(grid)\n",
        "    if show_figures2 == True:\n",
        "        def read(params,i):\n",
        "            FiN = params[\"path\"] + params[\"subm\"][i][\"name\"] + \".csv\"\n",
        "            target_name_back = {'target':params[\"target\"],'pred':params[\"target\"]}\n",
        "            return pd.read_csv(FiN).rename(columns=target_name_back)\n",
        "        dfs = [read(params,i) for i in range(len(params[\"subm\"]))] + [df_cross]\n",
        "        _height = 358 if len(params[\"subm\"]) == 11 else 254\n",
        "        f   = figure(width=785, height=_height)\n",
        "        f.title.text = 'Click on legend entries to mute the corresponding lines'\n",
        "        b,e        = 1000,1121\n",
        "        line_x     = [dfs[i][b:e]['id']             for i in range(len(dfs))]\n",
        "        line_y     = [dfs[i][b:e]['sales'] for i in range(len(dfs))]\n",
        "        color      = colors + [color_cross]\n",
        "        alpha      = [0.8 for i in range(len(dfs)-1)] + [0.95]\n",
        "        lws        = [1.0 for i in range(len(dfs)-1)] + [1.00]\n",
        "        legend = subm_names + ['cross']\n",
        "        for i in range(len(legend)):\n",
        "            f.line(line_x[i], line_y[i], line_width=lws[i], color=color[i], alpha=alpha[i],\n",
        "                   muted_color='white',legend_label=legend[i])\n",
        "        f.legend.location = \"top_left\"\n",
        "        f.legend.click_policy=\"mute\"\n",
        "        show(f)\n",
        "\n",
        "\n",
        "def matrix_vs(path,fs_names):\n",
        "    def load(path,fs_names):\n",
        "        dfs = [pd.read_csv(path + name_subm +'.csv') for name_subm in fs_names]\n",
        "        for i in range(len(dfs)):\n",
        "            dfs[i] = dfs[i].rename(columns={\"sales\": f'{fs_names[i]}'})\n",
        "        dfsm = pd.merge(dfs[0], dfs[1], on=\"id\")\n",
        "        for i in range(2,len(dfs)):\n",
        "            dfsm = pd.merge(dfsm,dfs[i],on='id')\n",
        "        return dfsm\n",
        "    def make_list_vs(fs_names):\n",
        "        list = []\n",
        "        for i in range(0,len(fs_names)-1):\n",
        "            for j in range(i+1,len(fs_names)):\n",
        "                list.append(fs_names[i] + \"_vs_\" + fs_names[j])\n",
        "        return list\n",
        "    def get_mvs(dfs, list_vs):\n",
        "        def get_abs_distance(x,t1,t2):\n",
        "            return abs(x[t1]-x[t2])\n",
        "        for vs in list_vs:\n",
        "            t = vs.split('_vs_')\n",
        "            dfs[vs] = dfs.apply(lambda x: get_abs_distance(x,t[0],t[1]), axis=1)\n",
        "        return dfs\n",
        "    def distance_vs(name, st_names, list_vs, dfs):\n",
        "        distances = []\n",
        "        for st in st_names:\n",
        "            vs_between = name + \"_vs_\" + st\n",
        "            if vs_between not in list_vs:\n",
        "                distances.append(0)\n",
        "            else: distances.append(round(dfs[vs_between].sum()))\n",
        "        return distances\n",
        "    dfs = load(path,fs_names)\n",
        "    list_vs = make_list_vs(fs_names)\n",
        "    mvs = get_mvs(dfs, list_vs)\n",
        "    m1 = pd.DataFrame({'subm':fs_names})\n",
        "    m2 = pd.DataFrame({ name :distance_vs(name, fs_names, list_vs, mvs) for name in fs_names})\n",
        "    matrix = pd.concat([m1,m2],axis=1)\n",
        "    return matrix\n",
        "\n",
        "\n",
        "def seaborn_Show(params,file_name_cross=''):\n",
        "    import matplotlib.pyplot as plt, seaborn as sns\n",
        "    import warnings; warnings.filterwarnings('ignore')\n",
        "    plt.figure(figsize=(9, 3))\n",
        "    for subm in params['subm']:\n",
        "        pred = pd.read_csv(params['path']+subm['name']+'.csv')[params['id_target'][1]]\n",
        "        sns.kdeplot(pred, label = subm['name'], linewidth = 0.5)\n",
        "    if file_name_cross != '':\n",
        "        pred = pd.read_csv(file_name_cross)[params['id_target'][1]]\n",
        "        sns.kdeplot(pred, label = 'blend', linewidth = 1, linestyle = 'dashed')\n",
        "    plt.title(\"KDE\")\n",
        "    plt.xlabel(\"target\")\n",
        "    plt.ylabel(\"Density\")\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def display_distances(params):\n",
        "    files = [subm['name'] for subm in params['subm']]\n",
        "    distances = matrix_vs ( params['path'], files )\n",
        "    display(distances)\n",
        "\n",
        "\n",
        "def arr_colors(color):\n",
        "    sg = ['silver','gainsboro']\n",
        "    if color=='red'   or color=='r': return ['red','crimson','firebrick']            + sg\n",
        "    if color=='Red'   or color=='R': return ['red','tomato','crimson']               + sg\n",
        "    if color=='Green' or color=='G': return ['forestgreen','limegreen', 'darkgreen'] + sg\n",
        "    if color=='Blue'  or color=='B': return ['blue','royalblue','mediumblue']        + sg\n",
        "    if color=='RGB'   or color=='S': return ['mediumblue','darkgreen','crimson']     + sg\n",
        "    return ['black','dimgray','gray'] + sg\n",
        "\n",
        "\n",
        "def convert(schema):\n",
        "    colors = arr_colors(schema[2])\n",
        "    dicts  = [\n",
        "        {'name': schema[0][i],'weight':schema[1][i],'color':colors[i]}\n",
        "        for i in range(len(schema[0]))\n",
        "    ]\n",
        "    return {'subm':dicts}\n",
        "\n",
        "\n",
        "def h_blend(\n",
        "        params, _update={},\n",
        "        cross='silver',\n",
        "        details=False,\n",
        "        fig1=False, fig2=False, wf2=555,\n",
        "        dtls=False, dist=False, subm=''):\n",
        "\n",
        "    if isinstance(params, list): params = convert(params)\n",
        "\n",
        "    if 'path' in _update: params.update(_update)\n",
        "\n",
        "    color_cross, dk  = cross, copy.deepcopy(params)\n",
        "\n",
        "    if details == True:\n",
        "        dist = True\n",
        "        show_details,show_figures1,show_figures2 = True,True,True\n",
        "    else:\n",
        "        show_details,show_figures1,show_figures2 = dtls,fig1,fig2\n",
        "\n",
        "    show_figures2 = False\n",
        "\n",
        "    file_short_names = [subm['name'] for subm in params['subm']]\n",
        "    type_sort    = params['type_sort'][0]\n",
        "    dk['asc']    = params['type_sort'][1]\n",
        "    dk['desc']   = params['type_sort'][2]\n",
        "    dk['id']     = params['id_target'][0]\n",
        "    dk['target'] = params['id_target'][1]\n",
        "# ------------------------------------------------------------------------\n",
        "    def read(dk,i):\n",
        "        tnm = dk[\"subm\"][i][\"name\"]\n",
        "        FiN = dk[\"path\"] + tnm + \".csv\"\n",
        "        return pd.read_csv(FiN).rename(columns={\n",
        "            'target':tnm, 'pred':tnm, dk[\"target\"]:tnm})\n",
        "\n",
        "    def merge(dfs_subm):\n",
        "        df_subms = pd.merge(dfs_subm[0],  dfs_subm[1], on=[dk['id']])\n",
        "        for i in range(2, len(dk[\"subm\"])):\n",
        "            df_subms = pd.merge(df_subms, dfs_subm[i], on=[dk['id']])\n",
        "        return df_subms\n",
        "\n",
        "    def da(dk,sorting_direction,show_details):\n",
        "\n",
        "        df_subms = merge([read(dk,i) for i in range(len(dk[\"subm\"]))])\n",
        "        cols = [col for col in df_subms.columns if col != dk['id']]\n",
        "        short_name_cols = [c for c in cols]\n",
        "\n",
        "        def alls1(x, sd=sorting_direction,cs=cols):\n",
        "            reverse = True if sd=='desc' else False\n",
        "            tes = {c: x[c] for c in cs}.items()\n",
        "            subms_sorted = [t[0] for t in sorted(tes,key=lambda k:k[1],reverse=reverse)]\n",
        "            return subms_sorted\n",
        "\n",
        "        import random\n",
        "\n",
        "        def alls2(x, sd=sorting_direction,cs=cols):\n",
        "            reverse = True if sd=='desc' else False\n",
        "            tes = {c: x[c] for c in cs}.items()\n",
        "            subms_random = [t[0] for t in tes]\n",
        "            random.shuffle(subms_random)\n",
        "            return subms_random\n",
        "\n",
        "        alls = alls1 if type_sort == 'asc/desc' else alls2\n",
        "\n",
        "        def summa(x,cs,wts,ic_alls):\n",
        "            return sum([x[cs[j]] * (wts[0][j] + wts[1][ic_alls[j]]) for j in range(len(cs))])\n",
        "\n",
        "        wts = [[[e['weight'] for e in dk[\"subm\"]], [w for w in dk[\"subwts\"]]]]\n",
        "\n",
        "        def correct(x, cs=cols, wts=wts):\n",
        "            i = [x['alls'].index(c) for c in short_name_cols]\n",
        "            return summa(x,cs,wts[0],i)\n",
        "\n",
        "        if len(wts) == 1:\n",
        "            correct_sub_weights = [wt for wt in dk[\"subwts\"]]\n",
        "            weights = [subm['weight'] for subm in dk[\"subm\"]]\n",
        "            def correct(x, cs=cols, w=weights, cw=correct_sub_weights):\n",
        "                ic = [x['alls'].index(c) for c in short_name_cols]\n",
        "                cS = [x[cols[j]] * (w[j] + cw[ic[j]]) for j in range(len(cols))]\n",
        "                return sum(cS)\n",
        "\n",
        "        if len(wts) > 1 or \"subwts2\" in dk:\n",
        "\n",
        "            wts = [\n",
        "                [[e['weight'] for e in dk[\"subm\"]], [w for w in dk[\"subwts\" ]]],\n",
        "                [[e['weight'] for e in dk[\"subm2\"]],[w for w in dk[\"subwts2\"]]],\n",
        "                [[e['weight'] for e in dk[\"subm3\"]],[w for w in dk[\"subwts3\"]]],\n",
        "            ]\n",
        "\n",
        "            def correct(x, cs=cols, wts=wts):\n",
        "                i = [x['alls'].index(c) for c in short_name_cols]\n",
        "                if   0.0540 < x['mx-m'] <= 0.0740: return summa(x,cs,wts[2],i)\n",
        "                if   0.0000 < x['mx-m'] <= 0.0050: return summa(x,cs,wts[1],i)\n",
        "                else:                              return summa(x,cs,wts[0],i)\n",
        "\n",
        "        def amxm(x, cs=cols):\n",
        "            list_values = x[cs].to_list()\n",
        "            mxm = abs(max(list_values)-min(list_values))\n",
        "            return mxm\n",
        "\n",
        "        if len(wts) > 1 or \"subwts2\" in dk:\n",
        "            df_subms['mx-m']   = df_subms.apply(lambda x: amxm   (x), axis=1)\n",
        "        df_subms['alls']       = df_subms.apply(lambda x: alls   (x), axis=1)\n",
        "        df_subms[dk[\"target\"]] = df_subms.apply(lambda x: correct(x), axis=1)\n",
        "        schema_rename = { old_nc:new_shnc for old_nc, new_shnc in zip(cols, short_name_cols) }\n",
        "        df_subms = df_subms.rename(columns=schema_rename)\n",
        "        df_subms = df_subms.rename(columns={dk[\"target\"]:\"ensemble\"})\n",
        "        df_subms.insert(loc=1, column=' _ ', value=['   '] * len(df_subms))\n",
        "        df_subms[' _ '] = df_subms[' _ '].astype(str)\n",
        "        pd.set_option('display.max_rows',100)\n",
        "        pd.set_option('display.float_format', '{:.5f}'.format)\n",
        "        if len(wts) > 1:\n",
        "            vcols = [dk['id']] + [' _ '] + short_name_cols + [' _ '] + ['mx-m'] + [' _ '] +\\\n",
        "                      ['alls'] + [' _ '] + ['ensemble']\n",
        "        else:\n",
        "            vcols = [dk['id']] + [' _ '] + short_name_cols + [' _ '] +\\\n",
        "                      ['alls'] + [' _ '] + ['ensemble']\n",
        "        df_subms = df_subms[vcols]\n",
        "        if show_details and sorting_direction=='desc': display(df_subms.head(5))\n",
        "        pd.set_option('display.float_format', '{:.5f}'.format)\n",
        "        df_subms = df_subms.rename(columns={\"ensemble\":dk[\"target\"]})\n",
        "        if sorting_direction=='desc':\n",
        "            df_subms.to_csv(f'tida_{sorting_direction}.csv', index=False)\n",
        "        return df_subms[[dk['id'],dk['target']]]\n",
        "\n",
        "    def ensemble_da(dk,        show_details):\n",
        "        dfD    = da(dk,'desc', show_details)\n",
        "        dfA    = da(dk,'asc',  show_details)\n",
        "        dfA[dk['target']] = dk['desc']*dfD[dk['target']] + dfA[dk['target']]*dk['asc']\n",
        "        return dfA\n",
        "\n",
        "    da = ensemble_da(dk,show_details)\n",
        "\n",
        "    bokeh_show(dk, da, show_figures1, show_figures2, wf2, color_cross)\n",
        "\n",
        "    if subm != '': da.to_csv(subm, index=False)\n",
        "\n",
        "    if dist == True:\n",
        "        added = False\n",
        "        if subm != '' and '/kaggle/working/' in params['path']:\n",
        "            params['subm'].append({'name':subm.replace('.csv','').replace(params['path'],'')})\n",
        "            added = True\n",
        "        display_distances(params)\n",
        "        cross_FiN = subm if not added else ''\n",
        "        seaborn_Show(params, file_name_cross=cross_FiN)\n",
        "\n",
        "    return  da"
      ],
      "metadata": {
        "trusted": true,
        "jupyter": {
          "source_hidden": true
        },
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2025-12-22T16:34:15.289907Z",
          "iopub.execute_input": "2025-12-22T16:34:15.291121Z",
          "iopub.status.idle": "2025-12-22T16:34:15.499258Z",
          "shell.execute_reply.started": "2025-12-22T16:34:15.291052Z",
          "shell.execute_reply": "2025-12-22T16:34:15.498315Z"
        },
        "id": "DakLXqXU2O-p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## h-blend\n",
        "\n",
        "[h-blend](https://www.kaggle.com/nina2025/writeups) - horizontal blend"
      ],
      "metadata": {
        "id": "gP27Mb3v2O-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version.1,4"
      ],
      "metadata": {
        "id": "I2zMb20T2O-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "      'path'     : f'/kaggle/input/2025-12-22-store-sales-time-series-forecasting/',\n",
        "      'id_target': ['id',\"sales\",],\n",
        "      'type_sort': ['asc/desc',0.30,0.70 ],\n",
        "      'subwts'   : [w/100 for w in [ +14, -1,-5,-8 ]],\n",
        "      'subm'     : [\n",
        "          {'name': f'0.37982', 'weight':+0.30, 'color':'royalblue'},\n",
        "          {'name': f'0.37984', 'weight':+0.10, 'color':'orange'   },\n",
        "          {'name': f'0.38006', 'weight':+0.30, 'color':'green'    },\n",
        "          {'name': f'0.38040', 'weight':+0.30, 'color':'crimson'  },]\n",
        "}\n",
        "df4 = h_blend(params, details=True, subm='h-blend-1.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-22T17:16:17.539467Z",
          "iopub.execute_input": "2025-12-22T17:16:17.539794Z",
          "iopub.status.idle": "2025-12-22T17:16:25.317867Z",
          "shell.execute_reply.started": "2025-12-22T17:16:17.539772Z",
          "shell.execute_reply": "2025-12-22T17:16:25.316721Z"
        },
        "id": "ChH1okBj2O-u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version.2,3,5"
      ],
      "metadata": {
        "id": "7_Ggx80_2O-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "      'path'     : f'/kaggle/input/2025-12-22-store-sales-time-series-forecasting/',\n",
        "      'id_target': ['id',\"sales\",],\n",
        "      'type_sort': ['asc/desc',0.30,0.70 ],\n",
        "      'subwts'   : [w/100 for w in [ +10,-3,-7 ]],\n",
        "      'subm'     : [\n",
        "          {'name': f'0.37982', 'weight':+0.37, 'color':'royalblue'},\n",
        "          {'name': f'0.38006', 'weight':+0.33, 'color':'orange'   },\n",
        "          {'name': f'0.38040', 'weight':+0.30, 'color':'green'    },]\n",
        "}\n",
        "df5 = h_blend(params, details=True, subm='h-blend-2.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-22T17:21:17.787957Z",
          "iopub.execute_input": "2025-12-22T17:21:17.789003Z",
          "iopub.status.idle": "2025-12-22T17:21:24.074312Z",
          "shell.execute_reply.started": "2025-12-22T17:21:17.788968Z",
          "shell.execute_reply": "2025-12-22T17:21:24.072784Z"
        },
        "id": "qItUCkXz2O-w"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for file in 'h-blend-1,h-blend-2,tida_desc'.split(','): os.remove(file +'.csv')"
      ],
      "metadata": {
        "trusted": true,
        "id": "VDFj9iGy2O-y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit"
      ],
      "metadata": {
        "id": "sdf1YRTj2O-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df5"
      ],
      "metadata": {
        "trusted": true,
        "id": "_ae6z_d32O-z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('submission.csv',index=False)\n",
        "df"
      ],
      "metadata": {
        "trusted": true,
        "id": "6K--v0ZX2O_P"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}